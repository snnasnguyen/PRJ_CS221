{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f2265d5ccf0b416fae2de7e5332582e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_40c33599f8de4774ae0afa6c6d98fa62","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bfdf44198257419ab462b0d06f3a8f4d","IPY_MODEL_39dc35b5de034fcbabbb196b2b814445","IPY_MODEL_e05f20a6a64d439a8f7aeee12c5e2890"]}},"40c33599f8de4774ae0afa6c6d98fa62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bfdf44198257419ab462b0d06f3a8f4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3e5388707c494351b6bd10cfce5e34b6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bad6a42afa5e45e7936d9d16d7c2b089"}},"39dc35b5de034fcbabbb196b2b814445":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0c1a7cbba51d4bf3b13e1deb4d126413","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_399586bed2014faeb88bd5c5267a9749"}},"e05f20a6a64d439a8f7aeee12c5e2890":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bf99de8acdb1479bb3d2c2f78cb85c2f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 420M/420M [00:08&lt;00:00, 49.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5359bd86b9474f948f0c58ddbca21270"}},"3e5388707c494351b6bd10cfce5e34b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bad6a42afa5e45e7936d9d16d7c2b089":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0c1a7cbba51d4bf3b13e1deb4d126413":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"399586bed2014faeb88bd5c5267a9749":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bf99de8acdb1479bb3d2c2f78cb85c2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5359bd86b9474f948f0c58ddbca21270":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9900763,"sourceType":"datasetVersion","datasetId":6081884}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers evaluate","metadata":{"id":"DE9Wlhn0Dmww","trusted":true,"execution":{"iopub.status.busy":"2025-01-20T10:06:57.911287Z","iopub.status.idle":"2025-01-20T10:06:57.911633Z","shell.execute_reply.started":"2025-01-20T10:06:57.911489Z","shell.execute_reply":"2025-01-20T10:06:57.911506Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import requests\nimport json\nimport torch\nimport os\nfrom tqdm import tqdm\nimport pandas as pd\nimport datasets\n","metadata":{"id":"0KQI4beK724N","trusted":true,"execution":{"iopub.status.busy":"2025-01-20T10:06:57.915630Z","iopub.status.idle":"2025-01-20T10:06:57.916046Z","shell.execute_reply.started":"2025-01-20T10:06:57.915832Z","shell.execute_reply":"2025-01-20T10:06:57.915854Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom huggingface_hub import login\n\nhf_token = os.getenv(\"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\")\nlogin(token=hf_token)\nprint(\"Logged in successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T10:06:57.917374Z","iopub.status.idle":"2025-01-20T10:06:57.917790Z","shell.execute_reply.started":"2025-01-20T10:06:57.917575Z","shell.execute_reply":"2025-01-20T10:06:57.917596Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the training dataset and take a look at it\nwith open('/kaggle/input/viquadv1/ViQuAD/train_ViQuAD.json', 'rb') as f:\n  squad = json.load(f)","metadata":{"id":"X3ULhdPV9OBa","trusted":true,"execution":{"iopub.status.busy":"2025-01-20T10:06:57.920039Z","iopub.status.idle":"2025-01-20T10:06:57.920495Z","shell.execute_reply.started":"2025-01-20T10:06:57.920236Z","shell.execute_reply":"2025-01-20T10:06:57.920261Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Each 'data' dict has two keys (title and paragraphs)\nsquad['data'][0].keys()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U0y6ra5A_pwX","outputId":"0967ad6d-90ef-4ddf-c18f-d474737fb2a8","trusted":true,"execution":{"iopub.status.busy":"2025-01-20T10:06:57.921510Z","iopub.status.idle":"2025-01-20T10:06:57.921939Z","shell.execute_reply.started":"2025-01-20T10:06:57.921718Z","shell.execute_reply":"2025-01-20T10:06:57.921740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"squad['data'][0]['paragraphs'][0]['context']","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156},"id":"NnyjqufICgGS","outputId":"12d02d90-d5e5-44b9-c6b3-43402eb8fd05","trusted":true,"execution":{"iopub.status.busy":"2025-01-20T10:06:57.923767Z","iopub.status.idle":"2025-01-20T10:06:57.924190Z","shell.execute_reply.started":"2025-01-20T10:06:57.923964Z","shell.execute_reply":"2025-01-20T10:06:57.923986Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def read_data(path):\n  # load the json file\n  with open(path, 'rb') as f:\n    squad = json.load(f)\n\n  data = []\n\n  for group in squad['data']:\n    title = group['title']\n      \n    for passage in group['paragraphs']:\n      context = passage['context']\n      for qa in passage['qas']:\n        question = qa['question']\n        id = qa['id']\n        if len(qa['answers']) == 0:\n            continue\n        answer_start = []\n        answer_text = []\n        for t in range(len(qa['answers'])):\n            answer_start.append(qa['answers'][t]['answer_start'])\n            answer_text.append(qa['answers'][t]['text'])\n        data.append({\n          'id':id,\n          'title':title,\n          'context': context,\n          'question': question ,\n          'answers':{\n                  'text':answer_text,\n                  'answer_start':answer_start\n              }\n          \n        })\n  tdata = pd.DataFrame(data)\n  tdata = datasets.Dataset.from_pandas(tdata)\n  return tdata\n","metadata":{"id":"F5wGx6bJ-BJC","trusted":true,"execution":{"iopub.status.busy":"2025-01-20T10:06:57.925513Z","iopub.status.idle":"2025-01-20T10:06:57.925933Z","shell.execute_reply.started":"2025-01-20T10:06:57.925716Z","shell.execute_reply":"2025-01-20T10:06:57.925740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_train = read_data('/kaggle/input/viquadv1/ViQuAD/train_ViQuAD.json')\ndata_valid = read_data('/kaggle/input/viquadv1/ViQuAD/dev_ViQuAD.json')","metadata":{"id":"An5wY1MNEwrt","trusted":true,"execution":{"iopub.status.busy":"2025-01-20T10:06:57.927117Z","iopub.status.idle":"2025-01-20T10:06:57.927561Z","shell.execute_reply.started":"2025-01-20T10:06:57.927315Z","shell.execute_reply":"2025-01-20T10:06:57.927357Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_valid","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T10:06:57.928873Z","iopub.status.idle":"2025-01-20T10:06:57.929173Z","shell.execute_reply.started":"2025-01-20T10:06:57.929026Z","shell.execute_reply":"2025-01-20T10:06:57.929041Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained('haidangnguyen467/finetune-xlm-r-base-uit-visquad-v1')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:06:23.050119Z","iopub.execute_input":"2025-01-19T15:06:23.050450Z","iopub.status.idle":"2025-01-19T15:06:23.944585Z","shell.execute_reply.started":"2025-01-19T15:06:23.050413Z","shell.execute_reply":"2025-01-19T15:06:23.943923Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"max_length = 384 \ndoc_stride = 128\npad_on_right = tokenizer.padding_side == \"right\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:06:23.945502Z","iopub.execute_input":"2025-01-19T15:06:23.945728Z","iopub.status.idle":"2025-01-19T15:06:23.950488Z","shell.execute_reply.started":"2025-01-19T15:06:23.945705Z","shell.execute_reply":"2025-01-19T15:06:23.949643Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"def prepare_train_features(data):\n    data[\"question\"] = [q.lstrip() for q in data[\"question\"]]\n\n    tokenized_data = tokenizer(\n        data[\"question\" if pad_on_right else \"context\"],\n        data[\"context\" if pad_on_right else \"question\"],\n        truncation=\"only_second\" if pad_on_right else \"only_first\",\n        max_length=max_length,\n        stride=doc_stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    sample_mapping = tokenized_data.pop(\"overflow_to_sample_mapping\")\n    offset_mapping = tokenized_data.pop(\"offset_mapping\")\n\n    tokenized_data[\"start_positions\"] = []\n    tokenized_data[\"end_positions\"] = []\n\n    for i, offsets in enumerate(offset_mapping):\n        input_ids = tokenized_data[\"input_ids\"][i]\n        cls_index = input_ids.index(tokenizer.cls_token_id)\n\n        sequence_ids = tokenized_data.sequence_ids(i)\n\n        sample_index = sample_mapping[i]\n        answers = data[\"answers\"][sample_index]\n        if len(answers[\"answer_start\"]) == 0:\n            tokenized_data[\"start_positions\"].append(cls_index)\n            tokenized_data[\"end_positions\"].append(cls_index)\n        else:\n            start_char = answers[\"answer_start\"][0]\n            end_char = start_char + len(answers[\"text\"][0])\n\n            token_start_index = 0\n            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n                token_start_index += 1\n\n            token_end_index = len(input_ids) - 1\n            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n                token_end_index -= 1\n\n            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n                tokenized_data[\"start_positions\"].append(cls_index)\n                tokenized_data[\"end_positions\"].append(cls_index)\n            else:\n                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n                    token_start_index += 1\n                tokenized_data[\"start_positions\"].append(token_start_index - 1)\n                while offsets[token_end_index][1] >= end_char:\n                    token_end_index -= 1\n                tokenized_data[\"end_positions\"].append(token_end_index + 1)\n\n    return tokenized_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:06:23.951889Z","iopub.execute_input":"2025-01-19T15:06:23.952243Z","iopub.status.idle":"2025-01-19T15:06:23.964637Z","shell.execute_reply.started":"2025-01-19T15:06:23.952206Z","shell.execute_reply":"2025-01-19T15:06:23.963934Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"tokenized_train = data_train.map(prepare_train_features, batched=True, remove_columns=data_train.column_names)\ntokenized_valid = data_valid.map(prepare_train_features, batched=True, remove_columns=data_train.column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:06:23.965546Z","iopub.execute_input":"2025-01-19T15:06:23.965854Z","iopub.status.idle":"2025-01-19T15:06:36.486168Z","shell.execute_reply.started":"2025-01-19T15:06:23.965822Z","shell.execute_reply":"2025-01-19T15:06:36.485295Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/18579 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e909346f7b144b609adec2ce43a4eba3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2285 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"121316691ed44d938fa9e9e68a9e41b7"}},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"decoded_answer = tokenizer.decode(tokenized_valid[0][\"input_ids\"][tokenized_valid[0][\"start_positions\"]:tokenized_valid[0][\"end_positions\"] + 1])\nprint(\"Decoded answer:\", decoded_answer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:06:36.488911Z","iopub.execute_input":"2025-01-19T15:06:36.489200Z","iopub.status.idle":"2025-01-19T15:06:36.498238Z","shell.execute_reply.started":"2025-01-19T15:06:36.489174Z","shell.execute_reply":"2025-01-19T15:06:36.497307Z"}},"outputs":[{"name":"stdout","text":"Decoded answer: nằm ở điểm gặp nhau của các hành trình thương mại đường bộ và đường sông\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"decoded_token = tokenizer.decode(tokenized_train[0][\"input_ids\"]) \nprint(\"Decoded token:\", decoded_token)\n\ndecoded_answer = tokenizer.decode(tokenized_train[0][\"input_ids\"][tokenized_train[0][\"start_positions\"]:tokenized_train[0][\"end_positions\"] + 1])\nprint(\"Decoded answer:\", decoded_answer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:06:36.499310Z","iopub.execute_input":"2025-01-19T15:06:36.499623Z","iopub.status.idle":"2025-01-19T15:06:36.523077Z","shell.execute_reply.started":"2025-01-19T15:06:36.499588Z","shell.execute_reply":"2025-01-19T15:06:36.520195Z"}},"outputs":[{"name":"stdout","text":"Decoded token: <s> Tên gọi nào được Phạm Văn Đồng sử dụng khi làm Phó chủ nhiệm cơ quan Biện sự xứ tại Quế Lâm?</s></s> Phạm Văn Đồng (1 tháng 3 năm 1906 – 29 tháng 4 năm 2000) là Thủ tướng đầu tiên của nước Cộng hòa Xã hội chủ nghĩa Việt Nam từ năm 1976 (từ năm 1981 gọi là Chủ tịch Hội đồng Bộ trưởng) cho đến khi nghỉ hưu năm 1987. Trước đó ông từng giữ chức vụ Thủ tướng Chính phủ Việt Nam Dân chủ Cộng hòa từ năm 1955 đến năm 1976. Ông là vị Thủ tướng Việt Nam tại vị lâu nhất (1955–1987). Ông là học trò, cộng sự của Chủ tịch Hồ Chí Minh. Ông có tên gọi thân mật là Tô, đây từng là bí danh của ông. Ông còn có tên gọi là Lâm Bá Kiệt khi làm Phó chủ nhiệm cơ quan Biện sự xứ tại Quế Lâm (Chủ nhiệm là Hồ Học Lãm).</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\nDecoded answer: Lâm Bá Kiệt\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"data_train[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:06:36.524359Z","iopub.execute_input":"2025-01-19T15:06:36.524621Z","iopub.status.idle":"2025-01-19T15:06:36.532711Z","shell.execute_reply.started":"2025-01-19T15:06:36.524595Z","shell.execute_reply":"2025-01-19T15:06:36.531918Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"{'id': 'uit_01__05272_0_1',\n 'title': 'Phạm Văn Đồng',\n 'context': 'Phạm Văn Đồng (1 tháng 3 năm 1906 – 29 tháng 4 năm 2000) là Thủ tướng đầu tiên của nước Cộng hòa Xã hội chủ nghĩa Việt Nam từ năm 1976 (từ năm 1981 gọi là Chủ tịch Hội đồng Bộ trưởng) cho đến khi nghỉ hưu năm 1987. Trước đó ông từng giữ chức vụ Thủ tướng Chính phủ Việt Nam Dân chủ Cộng hòa từ năm 1955 đến năm 1976. Ông là vị Thủ tướng Việt Nam tại vị lâu nhất (1955–1987). Ông là học trò, cộng sự của Chủ tịch Hồ Chí Minh. Ông có tên gọi thân mật là Tô, đây từng là bí danh của ông. Ông còn có tên gọi là Lâm Bá Kiệt khi làm Phó chủ nhiệm cơ quan Biện sự xứ tại Quế Lâm (Chủ nhiệm là Hồ Học Lãm).',\n 'question': 'Tên gọi nào được Phạm Văn Đồng sử dụng khi làm Phó chủ nhiệm cơ quan Biện sự xứ tại Quế Lâm?',\n 'answers': {'answer_start': [507], 'text': ['Lâm Bá Kiệt']}}"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nimport numpy as np\nimport collections\nfrom transformers import EvalPrediction\n\n\ndef compute_metrics(p: EvalPrediction, tokenizer):\n    \n    predictions, labels = p.predictions, p.label_ids\n\n    em, f1 = compute_em_and_f1(predictions, labels, tokenizer)\n    \n    return {\n        'em': em,\n        'f1': f1\n    }\n\ndef compute_em_and_f1(predictions, labels, tokenizer):\n    pred_answers = decode_predictions(predictions, tokenizer)\n    true_answers = decode_labels(labels, tokenizer)\n\n    em, f1 = 0, 0\n    for pred, true in zip(pred_answers, true_answers):\n        # print(f\"Pred: {pred}\")\n        # print(f\"True: {true}\")\n        em += exact_match(pred, true)\n        f1 += f1_score(pred, true)\n\n    em = em / len(pred_answers)\n    f1 = f1 / len(pred_answers)\n    return em, f1\n\ndef decode_predictions(predictions, tokenizer):\n    start_logits, end_logits = predictions\n    start_logits = torch.tensor(start_logits) \n    end_logits = torch.tensor(end_logits)      \n\n    start_positions = torch.argmax(start_logits, dim=-1)  \n    end_positions = torch.argmax(end_logits, dim=-1)     \n    \n    answers = []\n    for idx, (start, end) in enumerate(zip(start_positions, end_positions)):\n        \n        if start <= end:\n            answer = tokenizer.decode(tokenized_valid[idx][\"input_ids\"][start.item(): end.item() + 1])\n            answers.append(answer)\n        else:\n            answers.append('')  \n    return answers\ndef decode_labels(labels, tokenizer):\n\n    start_positions, end_positions = labels\n        \n    answers = []\n    for idx, (start, end) in enumerate(zip(start_positions, end_positions)):\n        if start <= end:\n            answer = tokenizer.decode(tokenized_valid[idx][\"input_ids\"][start.item(): end.item() + 1])\n            answers.append(answer)\n        else:\n            answers.append('')  \n    return answers\n\ndef exact_match(prediction, ground_truth):\n    \n    return int(prediction == ground_truth)\n\ndef f1_score(prediction, ground_truth):\n\n    prediction_tokens = prediction.split()\n    ground_truth_tokens = ground_truth.split()\n\n    common = collections.Counter(prediction_tokens) & collections.Counter(ground_truth_tokens)\n    num_common = sum(common.values())\n\n    if num_common == 0:\n        return 0.0\n\n    precision = num_common / len(prediction_tokens)\n    recall = num_common / len(ground_truth_tokens)\n    return (2 * precision * recall) / (precision + recall)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:06:36.534338Z","iopub.execute_input":"2025-01-19T15:06:36.534923Z","iopub.status.idle":"2025-01-19T15:06:36.554309Z","shell.execute_reply.started":"2025-01-19T15:06:36.534866Z","shell.execute_reply":"2025-01-19T15:06:36.553432Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\nmodel = AutoModelForQuestionAnswering.from_pretrained(\"haidangnguyen467/finetune-xlm-r-base-uit-visquad-v1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:06:36.555561Z","iopub.execute_input":"2025-01-19T15:06:36.555912Z","iopub.status.idle":"2025-01-19T15:06:36.685275Z","shell.execute_reply.started":"2025-01-19T15:06:36.555857Z","shell.execute_reply":"2025-01-19T15:06:36.684337Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"import os\n\nos.makedirs(\"xlm_r_finetune\", exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:06:36.686506Z","iopub.execute_input":"2025-01-19T15:06:36.686902Z","iopub.status.idle":"2025-01-19T15:06:36.694377Z","shell.execute_reply.started":"2025-01-19T15:06:36.686850Z","shell.execute_reply":"2025-01-19T15:06:36.693297Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"import wandb\n\ntotal = len(data_train)\nbatch_size = 32 \nst = int(total / 32)\nsave = int(total / 2)\nwandb_api = '5b506fee220b4162bcdedb46157cd237552aa7f0'\nwandb.login(key=wandb_api)\n\nargs = TrainingArguments(\n    output_dir = './xlm_r_finetune',\n    eval_strategy = \"steps\",\n    logging_strategy = \"steps\",\n    eval_steps=st,\n    logging_steps=st,\n    save_steps=save,\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    gradient_accumulation_steps=1,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    metric_for_best_model='f1',\n    save_total_limit=10,\n    push_to_hub=True,\n    hub_token=\"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\",\n    report_to=\"wandb\"  # Báo cáo lên WandB\n\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T16:26:46.655742Z","iopub.execute_input":"2025-01-19T16:26:46.656441Z","iopub.status.idle":"2025-01-19T16:26:46.688810Z","shell.execute_reply.started":"2025-01-19T16:26:46.656407Z","shell.execute_reply":"2025-01-19T16:26:46.688177Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"from transformers import default_data_collator\ndata_collator = default_data_collator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T16:26:47.984075Z","iopub.execute_input":"2025-01-19T16:26:47.984876Z","iopub.status.idle":"2025-01-19T16:26:47.989252Z","shell.execute_reply.started":"2025-01-19T16:26:47.984846Z","shell.execute_reply":"2025-01-19T16:26:47.988321Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"import gc\ngc.collect()\ntrainer = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T16:26:48.208014Z","iopub.execute_input":"2025-01-19T16:26:48.208277Z","iopub.status.idle":"2025-01-19T16:26:48.600328Z","shell.execute_reply.started":"2025-01-19T16:26:48.208252Z","shell.execute_reply":"2025-01-19T16:26:48.599504Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T16:26:48.601606Z","iopub.execute_input":"2025-01-19T16:26:48.601951Z","iopub.status.idle":"2025-01-19T16:26:48.611039Z","shell.execute_reply.started":"2025-01-19T16:26:48.601916Z","shell.execute_reply":"2025-01-19T16:26:48.610250Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_valid,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=lambda p: compute_metrics(p, tokenizer)  # Truyền tokenizer vào\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T16:26:48.619430Z","iopub.execute_input":"2025-01-19T16:26:48.619656Z","execution_failed":"2025-01-19T16:27:16.174Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='44' max='12420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   44/12420 00:52 < 4:16:01, 0.81 it/s, Epoch 0.07/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"checkpoint_path = '/kaggle/working/xlm_r_finetune/checkpoint-12420'\ntokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n\n# Load model\nmodel = AutoModelForQuestionAnswering.from_pretrained(checkpoint_path)\n\nmodel.push_to_hub(\"haidangnguyen467/finetune-xlm-r-base-uit-visquad-v1_3\", use_auth_token=\"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\")\ntokenizer.push_to_hub(\"haidangnguyen467/finetune-xlm-r-base-uit-visquad-v1_3\", use_auth_token=\"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\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T16:27:16.174Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import pipeline\ncheckpoint_path = 'haidangnguyen467/finetune-xlm-r-base-uit-visquad-v1_2'\ntokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n\n# Load model\nmodel = AutoModelForQuestionAnswering.from_pretrained(checkpoint_path)\nquestion_answerer = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n\ncontext = \"\"\"\nNhóm của chúng tôi là sinh viên năm 3 trường đại học công nghệ thông tin. Nhóm gồm 2 thành viên : Hoàng Đức Chung, Nguyễn Hải Đăng. Đây là đồ án cuối kỳ NLP . \n\"\"\"\nquestion = \"2 thành viên trong nhóm gồm những ai ?\"\nquestion_answerer(question=question, context=context)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T16:18:09.552009Z","iopub.execute_input":"2025-01-19T16:18:09.552384Z","iopub.status.idle":"2025-01-19T16:18:39.023623Z","shell.execute_reply.started":"2025-01-19T16:18:09.552356Z","shell.execute_reply":"2025-01-19T16:18:39.022654Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f5ced9df1e54a6fadbd80629c48d3b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5532a614a804951aff86c9521b94585"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"541e7082205d4a51b10581318de9a0a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae7e5b00c53b443ebeb5ac66f9687611"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ac0806a8ccc43028b54e01432305913"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c04ca127b99b49c99d47387a4c9ef13a"}},"metadata":{}},{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"{'score': 0.990077555179596,\n 'start': 99,\n 'end': 132,\n 'answer': 'Hoàng Đức Chung, Nguyễn Hải Đăng.'}"},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
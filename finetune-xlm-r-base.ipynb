{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-20T10:06:57.911287Z",
     "iopub.status.idle": "2025-01-20T10:06:57.911633Z",
     "shell.execute_reply": "2025-01-20T10:06:57.911506Z",
     "shell.execute_reply.started": "2025-01-20T10:06:57.911489Z"
    },
    "id": "DE9Wlhn0Dmww",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-20T10:06:57.915630Z",
     "iopub.status.idle": "2025-01-20T10:06:57.916046Z",
     "shell.execute_reply": "2025-01-20T10:06:57.915854Z",
     "shell.execute_reply.started": "2025-01-20T10:06:57.915832Z"
    },
    "id": "0KQI4beK724N",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-20T10:06:57.917374Z",
     "iopub.status.idle": "2025-01-20T10:06:57.917790Z",
     "shell.execute_reply": "2025-01-20T10:06:57.917596Z",
     "shell.execute_reply.started": "2025-01-20T10:06:57.917575Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "hf_token = os.getenv(\"\")\n",
    "login(token=hf_token)\n",
    "print(\"Logged in successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-20T10:06:57.920039Z",
     "iopub.status.idle": "2025-01-20T10:06:57.920495Z",
     "shell.execute_reply": "2025-01-20T10:06:57.920261Z",
     "shell.execute_reply.started": "2025-01-20T10:06:57.920236Z"
    },
    "id": "X3ULhdPV9OBa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the training dataset and take a look at it\n",
    "with open('/kaggle/input/viquadv1/ViQuAD/train_ViQuAD.json', 'rb') as f:\n",
    "  squad = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2025-01-20T10:06:57.921510Z",
     "iopub.status.idle": "2025-01-20T10:06:57.921939Z",
     "shell.execute_reply": "2025-01-20T10:06:57.921740Z",
     "shell.execute_reply.started": "2025-01-20T10:06:57.921718Z"
    },
    "id": "U0y6ra5A_pwX",
    "outputId": "0967ad6d-90ef-4ddf-c18f-d474737fb2a8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Each 'data' dict has two keys (title and paragraphs)\n",
    "squad['data'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "execution": {
     "iopub.status.busy": "2025-01-20T10:06:57.923767Z",
     "iopub.status.idle": "2025-01-20T10:06:57.924190Z",
     "shell.execute_reply": "2025-01-20T10:06:57.923986Z",
     "shell.execute_reply.started": "2025-01-20T10:06:57.923964Z"
    },
    "id": "NnyjqufICgGS",
    "outputId": "12d02d90-d5e5-44b9-c6b3-43402eb8fd05",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "squad['data'][0]['paragraphs'][0]['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-20T10:06:57.925513Z",
     "iopub.status.idle": "2025-01-20T10:06:57.925933Z",
     "shell.execute_reply": "2025-01-20T10:06:57.925740Z",
     "shell.execute_reply.started": "2025-01-20T10:06:57.925716Z"
    },
    "id": "F5wGx6bJ-BJC",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "  # load the json file\n",
    "  with open(path, 'rb') as f:\n",
    "    squad = json.load(f)\n",
    "\n",
    "  data = []\n",
    "\n",
    "  for group in squad['data']:\n",
    "    title = group['title']\n",
    "      \n",
    "    for passage in group['paragraphs']:\n",
    "      context = passage['context']\n",
    "      for qa in passage['qas']:\n",
    "        question = qa['question']\n",
    "        id = qa['id']\n",
    "        if len(qa['answers']) == 0:\n",
    "            continue\n",
    "        answer_start = []\n",
    "        answer_text = []\n",
    "        for t in range(len(qa['answers'])):\n",
    "            answer_start.append(qa['answers'][t]['answer_start'])\n",
    "            answer_text.append(qa['answers'][t]['text'])\n",
    "        data.append({\n",
    "          'id':id,\n",
    "          'title':title,\n",
    "          'context': context,\n",
    "          'question': question ,\n",
    "          'answers':{\n",
    "                  'text':answer_text,\n",
    "                  'answer_start':answer_start\n",
    "              }\n",
    "          \n",
    "        })\n",
    "  tdata = pd.DataFrame(data)\n",
    "  tdata = datasets.Dataset.from_pandas(tdata)\n",
    "  return tdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-20T10:06:57.927117Z",
     "iopub.status.idle": "2025-01-20T10:06:57.927561Z",
     "shell.execute_reply": "2025-01-20T10:06:57.927357Z",
     "shell.execute_reply.started": "2025-01-20T10:06:57.927315Z"
    },
    "id": "An5wY1MNEwrt",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_train = read_data('/kaggle/input/viquadv1/ViQuAD/train_ViQuAD.json')\n",
    "data_valid = read_data('/kaggle/input/viquadv1/ViQuAD/dev_ViQuAD.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-20T10:06:57.928873Z",
     "iopub.status.idle": "2025-01-20T10:06:57.929173Z",
     "shell.execute_reply": "2025-01-20T10:06:57.929041Z",
     "shell.execute_reply.started": "2025-01-20T10:06:57.929026Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T15:06:23.050450Z",
     "iopub.status.busy": "2025-01-19T15:06:23.050119Z",
     "iopub.status.idle": "2025-01-19T15:06:23.944585Z",
     "shell.execute_reply": "2025-01-19T15:06:23.943923Z",
     "shell.execute_reply.started": "2025-01-19T15:06:23.050413Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('haidangnguyen467/finetune-xlm-r-base-uit-visquad-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T15:06:23.945728Z",
     "iopub.status.busy": "2025-01-19T15:06:23.945502Z",
     "iopub.status.idle": "2025-01-19T15:06:23.950488Z",
     "shell.execute_reply": "2025-01-19T15:06:23.949643Z",
     "shell.execute_reply.started": "2025-01-19T15:06:23.945705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_length = 384 \n",
    "doc_stride = 128\n",
    "pad_on_right = tokenizer.padding_side == \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T15:06:23.952243Z",
     "iopub.status.busy": "2025-01-19T15:06:23.951889Z",
     "iopub.status.idle": "2025-01-19T15:06:23.964637Z",
     "shell.execute_reply": "2025-01-19T15:06:23.963934Z",
     "shell.execute_reply.started": "2025-01-19T15:06:23.952206Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_train_features(data):\n",
    "    data[\"question\"] = [q.lstrip() for q in data[\"question\"]]\n",
    "\n",
    "    tokenized_data = tokenizer(\n",
    "        data[\"question\" if pad_on_right else \"context\"],\n",
    "        data[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_mapping = tokenized_data.pop(\"overflow_to_sample_mapping\")\n",
    "    offset_mapping = tokenized_data.pop(\"offset_mapping\")\n",
    "\n",
    "    tokenized_data[\"start_positions\"] = []\n",
    "    tokenized_data[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        input_ids = tokenized_data[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        sequence_ids = tokenized_data.sequence_ids(i)\n",
    "\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = data[\"answers\"][sample_index]\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_data[\"start_positions\"].append(cls_index)\n",
    "            tokenized_data[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_data[\"start_positions\"].append(cls_index)\n",
    "                tokenized_data[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_data[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_data[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T15:06:23.965854Z",
     "iopub.status.busy": "2025-01-19T15:06:23.965546Z",
     "iopub.status.idle": "2025-01-19T15:06:36.486168Z",
     "shell.execute_reply": "2025-01-19T15:06:36.485295Z",
     "shell.execute_reply.started": "2025-01-19T15:06:23.965822Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e909346f7b144b609adec2ce43a4eba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18579 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121316691ed44d938fa9e9e68a9e41b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2285 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = data_train.map(prepare_train_features, batched=True, remove_columns=data_train.column_names)\n",
    "tokenized_valid = data_valid.map(prepare_train_features, batched=True, remove_columns=data_train.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T15:06:36.489200Z",
     "iopub.status.busy": "2025-01-19T15:06:36.488911Z",
     "iopub.status.idle": "2025-01-19T15:06:36.498238Z",
     "shell.execute_reply": "2025-01-19T15:06:36.497307Z",
     "shell.execute_reply.started": "2025-01-19T15:06:36.489174Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded answer: nằm ở điểm gặp nhau của các hành trình thương mại đường bộ và đường sông\n"
     ]
    }
   ],
   "source": [
    "decoded_answer = tokenizer.decode(tokenized_valid[0][\"input_ids\"][tokenized_valid[0][\"start_positions\"]:tokenized_valid[0][\"end_positions\"] + 1])\n",
    "print(\"Decoded answer:\", decoded_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T15:06:36.499623Z",
     "iopub.status.busy": "2025-01-19T15:06:36.499310Z",
     "iopub.status.idle": "2025-01-19T15:06:36.523077Z",
     "shell.execute_reply": "2025-01-19T15:06:36.520195Z",
     "shell.execute_reply.started": "2025-01-19T15:06:36.499588Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded token: <s> Tên gọi nào được Phạm Văn Đồng sử dụng khi làm Phó chủ nhiệm cơ quan Biện sự xứ tại Quế Lâm?</s></s> Phạm Văn Đồng (1 tháng 3 năm 1906 – 29 tháng 4 năm 2000) là Thủ tướng đầu tiên của nước Cộng hòa Xã hội chủ nghĩa Việt Nam từ năm 1976 (từ năm 1981 gọi là Chủ tịch Hội đồng Bộ trưởng) cho đến khi nghỉ hưu năm 1987. Trước đó ông từng giữ chức vụ Thủ tướng Chính phủ Việt Nam Dân chủ Cộng hòa từ năm 1955 đến năm 1976. Ông là vị Thủ tướng Việt Nam tại vị lâu nhất (1955–1987). Ông là học trò, cộng sự của Chủ tịch Hồ Chí Minh. Ông có tên gọi thân mật là Tô, đây từng là bí danh của ông. Ông còn có tên gọi là Lâm Bá Kiệt khi làm Phó chủ nhiệm cơ quan Biện sự xứ tại Quế Lâm (Chủ nhiệm là Hồ Học Lãm).</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "Decoded answer: Lâm Bá Kiệt\n"
     ]
    }
   ],
   "source": [
    "decoded_token = tokenizer.decode(tokenized_train[0][\"input_ids\"]) \n",
    "print(\"Decoded token:\", decoded_token)\n",
    "\n",
    "decoded_answer = tokenizer.decode(tokenized_train[0][\"input_ids\"][tokenized_train[0][\"start_positions\"]:tokenized_train[0][\"end_positions\"] + 1])\n",
    "print(\"Decoded answer:\", decoded_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T15:06:36.524621Z",
     "iopub.status.busy": "2025-01-19T15:06:36.524359Z",
     "iopub.status.idle": "2025-01-19T15:06:36.532711Z",
     "shell.execute_reply": "2025-01-19T15:06:36.531918Z",
     "shell.execute_reply.started": "2025-01-19T15:06:36.524595Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'uit_01__05272_0_1',\n",
       " 'title': 'Phạm Văn Đồng',\n",
       " 'context': 'Phạm Văn Đồng (1 tháng 3 năm 1906 – 29 tháng 4 năm 2000) là Thủ tướng đầu tiên của nước Cộng hòa Xã hội chủ nghĩa Việt Nam từ năm 1976 (từ năm 1981 gọi là Chủ tịch Hội đồng Bộ trưởng) cho đến khi nghỉ hưu năm 1987. Trước đó ông từng giữ chức vụ Thủ tướng Chính phủ Việt Nam Dân chủ Cộng hòa từ năm 1955 đến năm 1976. Ông là vị Thủ tướng Việt Nam tại vị lâu nhất (1955–1987). Ông là học trò, cộng sự của Chủ tịch Hồ Chí Minh. Ông có tên gọi thân mật là Tô, đây từng là bí danh của ông. Ông còn có tên gọi là Lâm Bá Kiệt khi làm Phó chủ nhiệm cơ quan Biện sự xứ tại Quế Lâm (Chủ nhiệm là Hồ Học Lãm).',\n",
       " 'question': 'Tên gọi nào được Phạm Văn Đồng sử dụng khi làm Phó chủ nhiệm cơ quan Biện sự xứ tại Quế Lâm?',\n",
       " 'answers': {'answer_start': [507], 'text': ['Lâm Bá Kiệt']}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T15:06:36.534923Z",
     "iopub.status.busy": "2025-01-19T15:06:36.534338Z",
     "iopub.status.idle": "2025-01-19T15:06:36.554309Z",
     "shell.execute_reply": "2025-01-19T15:06:36.553432Z",
     "shell.execute_reply.started": "2025-01-19T15:06:36.534866Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import collections\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction, tokenizer):\n",
    "    \n",
    "    predictions, labels = p.predictions, p.label_ids\n",
    "\n",
    "    em, f1 = compute_em_and_f1(predictions, labels, tokenizer)\n",
    "    \n",
    "    return {\n",
    "        'em': em,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "def compute_em_and_f1(predictions, labels, tokenizer):\n",
    "    pred_answers = decode_predictions(predictions, tokenizer)\n",
    "    true_answers = decode_labels(labels, tokenizer)\n",
    "\n",
    "    em, f1 = 0, 0\n",
    "    for pred, true in zip(pred_answers, true_answers):\n",
    "        # print(f\"Pred: {pred}\")\n",
    "        # print(f\"True: {true}\")\n",
    "        em += exact_match(pred, true)\n",
    "        f1 += f1_score(pred, true)\n",
    "\n",
    "    em = em / len(pred_answers)\n",
    "    f1 = f1 / len(pred_answers)\n",
    "    return em, f1\n",
    "\n",
    "def decode_predictions(predictions, tokenizer):\n",
    "    start_logits, end_logits = predictions\n",
    "    start_logits = torch.tensor(start_logits) \n",
    "    end_logits = torch.tensor(end_logits)      \n",
    "\n",
    "    start_positions = torch.argmax(start_logits, dim=-1)  \n",
    "    end_positions = torch.argmax(end_logits, dim=-1)     \n",
    "    \n",
    "    answers = []\n",
    "    for idx, (start, end) in enumerate(zip(start_positions, end_positions)):\n",
    "        \n",
    "        if start <= end:\n",
    "            answer = tokenizer.decode(tokenized_valid[idx][\"input_ids\"][start.item(): end.item() + 1])\n",
    "            answers.append(answer)\n",
    "        else:\n",
    "            answers.append('')  \n",
    "    return answers\n",
    "def decode_labels(labels, tokenizer):\n",
    "\n",
    "    start_positions, end_positions = labels\n",
    "        \n",
    "    answers = []\n",
    "    for idx, (start, end) in enumerate(zip(start_positions, end_positions)):\n",
    "        if start <= end:\n",
    "            answer = tokenizer.decode(tokenized_valid[idx][\"input_ids\"][start.item(): end.item() + 1])\n",
    "            answers.append(answer)\n",
    "        else:\n",
    "            answers.append('')  \n",
    "    return answers\n",
    "\n",
    "def exact_match(prediction, ground_truth):\n",
    "    \n",
    "    return int(prediction == ground_truth)\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "\n",
    "    prediction_tokens = prediction.split()\n",
    "    ground_truth_tokens = ground_truth.split()\n",
    "\n",
    "    common = collections.Counter(prediction_tokens) & collections.Counter(ground_truth_tokens)\n",
    "    num_common = sum(common.values())\n",
    "\n",
    "    if num_common == 0:\n",
    "        return 0.0\n",
    "\n",
    "    precision = num_common / len(prediction_tokens)\n",
    "    recall = num_common / len(ground_truth_tokens)\n",
    "    return (2 * precision * recall) / (precision + recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T15:06:36.555912Z",
     "iopub.status.busy": "2025-01-19T15:06:36.555561Z",
     "iopub.status.idle": "2025-01-19T15:06:36.685275Z",
     "shell.execute_reply": "2025-01-19T15:06:36.684337Z",
     "shell.execute_reply.started": "2025-01-19T15:06:36.555857Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"haidangnguyen467/finetune-xlm-r-base-uit-visquad-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T15:06:36.686902Z",
     "iopub.status.busy": "2025-01-19T15:06:36.686506Z",
     "iopub.status.idle": "2025-01-19T15:06:36.694377Z",
     "shell.execute_reply": "2025-01-19T15:06:36.693297Z",
     "shell.execute_reply.started": "2025-01-19T15:06:36.686850Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"xlm_r_finetune\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T16:26:46.656441Z",
     "iopub.status.busy": "2025-01-19T16:26:46.655742Z",
     "iopub.status.idle": "2025-01-19T16:26:46.688810Z",
     "shell.execute_reply": "2025-01-19T16:26:46.688177Z",
     "shell.execute_reply.started": "2025-01-19T16:26:46.656407Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "total = len(data_train)\n",
    "batch_size = 32 \n",
    "st = int(total / 32)\n",
    "save = int(total / 2)\n",
    "wandb_api = '5b506fee220b4162bcdedb46157cd237552aa7f0'\n",
    "wandb.login(key=wandb_api)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir = './xlm_r_finetune',\n",
    "    eval_strategy = \"steps\",\n",
    "    logging_strategy = \"steps\",\n",
    "    eval_steps=st,\n",
    "    logging_steps=st,\n",
    "    save_steps=save,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    metric_for_best_model='f1',\n",
    "    save_total_limit=10,\n",
    "    push_to_hub=True,\n",
    "    hub_token=\"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\",\n",
    "    report_to=\"wandb\"  # Báo cáo lên WandB\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T16:26:47.984876Z",
     "iopub.status.busy": "2025-01-19T16:26:47.984075Z",
     "iopub.status.idle": "2025-01-19T16:26:47.989252Z",
     "shell.execute_reply": "2025-01-19T16:26:47.988321Z",
     "shell.execute_reply.started": "2025-01-19T16:26:47.984846Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import default_data_collator\n",
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T16:26:48.208277Z",
     "iopub.status.busy": "2025-01-19T16:26:48.208014Z",
     "iopub.status.idle": "2025-01-19T16:26:48.600328Z",
     "shell.execute_reply": "2025-01-19T16:26:48.599504Z",
     "shell.execute_reply.started": "2025-01-19T16:26:48.208252Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "trainer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T16:26:48.601951Z",
     "iopub.status.busy": "2025-01-19T16:26:48.601606Z",
     "iopub.status.idle": "2025-01-19T16:26:48.611039Z",
     "shell.execute_reply": "2025-01-19T16:26:48.610250Z",
     "shell.execute_reply.started": "2025-01-19T16:26:48.601916Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-19T16:27:16.174Z",
     "iopub.execute_input": "2025-01-19T16:26:48.619656Z",
     "iopub.status.busy": "2025-01-19T16:26:48.619430Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='12420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   44/12420 00:52 < 4:16:01, 0.81 it/s, Epoch 0.07/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_valid,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=lambda p: compute_metrics(p, tokenizer)  # Truyền tokenizer vào\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-19T16:27:16.174Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint_path = '/kaggle/working/xlm_r_finetune/checkpoint-12420'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(checkpoint_path)\n",
    "\n",
    "model.push_to_hub(\"haidangnguyen467/finetune-xlm-r-base-uit-visquad-v1_3\", use_auth_token=\"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\")\n",
    "tokenizer.push_to_hub(\"haidangnguyen467/finetune-xlm-r-base-uit-visquad-v1_3\", use_auth_token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T16:18:09.552384Z",
     "iopub.status.busy": "2025-01-19T16:18:09.552009Z",
     "iopub.status.idle": "2025-01-19T16:18:39.023623Z",
     "shell.execute_reply": "2025-01-19T16:18:39.022654Z",
     "shell.execute_reply.started": "2025-01-19T16:18:09.552356Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5ced9df1e54a6fadbd80629c48d3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5532a614a804951aff86c9521b94585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541e7082205d4a51b10581318de9a0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7e5b00c53b443ebeb5ac66f9687611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac0806a8ccc43028b54e01432305913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04ca127b99b49c99d47387a4c9ef13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.990077555179596,\n",
       " 'start': 99,\n",
       " 'end': 132,\n",
       " 'answer': 'Hoàng Đức Chung, Nguyễn Hải Đăng.'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "checkpoint_path = 'haidangnguyen467/finetune-xlm-r-base-uit-visquad-v1_2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(checkpoint_path)\n",
    "question_answerer = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "context = \"\"\"\n",
    "Nhóm của chúng tôi là sinh viên năm 3 trường đại học công nghệ thông tin. Nhóm gồm 2 thành viên : Hoàng Đức Chung, Nguyễn Hải Đăng. Đây là đồ án cuối kỳ NLP . \n",
    "\"\"\"\n",
    "question = \"2 thành viên trong nhóm gồm những ai ?\"\n",
    "question_answerer(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6081884,
     "sourceId": 9900763,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0c1a7cbba51d4bf3b13e1deb4d126413": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "399586bed2014faeb88bd5c5267a9749": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39dc35b5de034fcbabbb196b2b814445": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_399586bed2014faeb88bd5c5267a9749",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0c1a7cbba51d4bf3b13e1deb4d126413",
      "value": 440473133
     }
    },
    "3e5388707c494351b6bd10cfce5e34b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40c33599f8de4774ae0afa6c6d98fa62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5359bd86b9474f948f0c58ddbca21270": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bad6a42afa5e45e7936d9d16d7c2b089": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf99de8acdb1479bb3d2c2f78cb85c2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bfdf44198257419ab462b0d06f3a8f4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bad6a42afa5e45e7936d9d16d7c2b089",
      "placeholder": "​",
      "style": "IPY_MODEL_3e5388707c494351b6bd10cfce5e34b6",
      "value": "Downloading: 100%"
     }
    },
    "e05f20a6a64d439a8f7aeee12c5e2890": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5359bd86b9474f948f0c58ddbca21270",
      "placeholder": "​",
      "style": "IPY_MODEL_bf99de8acdb1479bb3d2c2f78cb85c2f",
      "value": " 420M/420M [00:08&lt;00:00, 49.1MB/s]"
     }
    },
    "f2265d5ccf0b416fae2de7e5332582e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bfdf44198257419ab462b0d06f3a8f4d",
       "IPY_MODEL_39dc35b5de034fcbabbb196b2b814445",
       "IPY_MODEL_e05f20a6a64d439a8f7aeee12c5e2890"
      ],
      "layout": "IPY_MODEL_40c33599f8de4774ae0afa6c6d98fa62"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
